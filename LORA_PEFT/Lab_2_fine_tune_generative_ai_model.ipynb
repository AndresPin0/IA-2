{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandoordonez/GenAI/blob/main/Lab_2_fine_tune_generative_ai_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzpMK6XbV7aR",
        "tags": []
      },
      "source": [
        "# Fine-Tune un modelo de Gen AI para Res√∫menes de Textos M√©dicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObK2CXbTV7aT"
      },
      "source": [
        "En este cuaderno, se har√° el fine-tune de un LLM existente de Hugging Face para mejorar el resumen de textos m√©dicos cient√≠ficos. Utilizar√° el modelo [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5), que proporciona un modelo tuneado con instrucciones de alta calidad y puede resumir texto m√©dico especializado. Para mejorar las inferencias, se usar√° full fine-tuning y evaluar√° los resultados con m√©tricas de ROUGE. Luego, se usar√° Parameter Efficient Fine-Tuning (PEFT), evaluar√° el modelo resultante y ver√° que los beneficios de PEFT superan las desventajas de rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE1nZWSwV7aU"
      },
      "source": [
        "# Tabla de contenido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuYTKFgPV7aU",
        "tags": []
      },
      "source": [
        "- [ 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM](#1)\n",
        "  - [ 1.1 - Set up Kernel and Required Dependencies](#1.1)\n",
        "  - [ 1.2 - Load Dataset and LLM](#1.2)\n",
        "  - [ 1.3 - Test the Model with Zero Shot Inferencing](#1.3)\n",
        "- [ 2 - Perform Full Fine-Tuning](#2)\n",
        "  - [ 2.1 - Preprocess the Medical Articles Dataset](#2.1)\n",
        "  - [ 2.2 - Fine-Tune the Model with the Preprocessed Dataset](#2.2)\n",
        "  - [ 2.3 - Evaluate the Model Qualitatively (Human Evaluation)](#2.3)\n",
        "  - [ 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#2.4)\n",
        "- [ 3 - Perform Parameter Efficient Fine-Tuning (PEFT)](#3)\n",
        "  - [ 3.1 - Setup the PEFT/LoRA model for Fine-Tuning](#3.1)\n",
        "  - [ 3.2 - Train PEFT Adapter](#3.2)\n",
        "  - [ 3.3 - Evaluate the Model Qualitatively (Human Evaluation)](#3.3)\n",
        "  - [ 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#3.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qBL7hyyV7aV"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.11\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Instalando PyTorch...\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch==2.8.0+cpu in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.8.0+cpu)\n",
            "Requirement already satisfied: torchvision in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.23.0+cpu)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.8.0+cpu)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.8.0+cpu) (4.15.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.8.0+cpu) (3.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.8.0+cpu) (1.13.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.8.0+cpu) (2024.6.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.8.0+cpu) (3.13.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.8.0+cpu) (3.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch==2.8.0+cpu) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.8.0+cpu) (2.1.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "üöÄ Instalando Transformers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.56.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (3.13.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from transformers==4.56.1) (25.0)\n",
            "Requirement already satisfied: requests in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (4.67.1)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (2.1.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (0.35.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (0.6.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.56.1) (2025.9.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (4.15.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers==4.56.1) (0.4.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.56.1) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.56.1) (2.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.56.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.56.1) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "üöÄ Instalando Datasets...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets==4.0.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (2.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (0.35.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (0.3.8)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (21.0.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (3.13.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (3.5.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from datasets==4.0.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (6.0.2)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (2024.6.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (2.32.5)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==4.0.0) (2.1.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets==4.0.0) (3.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets==4.0.0) (2025.8.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets==4.0.0) (2.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets==4.0.0) (3.10)\n",
            "Requirement already satisfied: colorama in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.66.3->datasets==4.0.0) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (5.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.20.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.3.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "üöÄ Instalando Evaluate...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate==0.4.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.5)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (2.1.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (4.67.1)\n",
            "Requirement already satisfied: dill in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (0.3.8)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (4.0.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (2.3.2)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (0.70.16)\n",
            "Requirement already satisfied: xxhash in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (3.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (2.32.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from evaluate==0.4.5) (0.35.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from evaluate==0.4.5) (25.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.5) (21.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.5) (6.0.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.5) (3.13.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (4.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.5) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.5) (2025.8.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.5) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.5) (2.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.62.1->evaluate==0.4.5) (0.4.6)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from pandas->evaluate==0.4.5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.20.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (0.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (25.3.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (5.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.4.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.5) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "üöÄ Instalando ROUGE Score...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge_score==0.1.2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score==0.1.2) (2.3.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score==0.1.2) (3.9.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score==0.1.2) (2.1.2)\n",
            "Requirement already satisfied: six>=1.14.0 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from rouge_score==0.1.2) (1.17.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score==0.1.2) (2025.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score==0.1.2) (8.2.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score==0.1.2) (4.67.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score==0.1.2) (1.5.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk->rouge_score==0.1.2) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "üöÄ Instalando PEFT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: peft==0.17.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.17.1)\n",
            "Requirement already satisfied: transformers in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (4.56.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from peft==0.17.1) (7.0.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (0.35.0)\n",
            "Requirement already satisfied: safetensors in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (0.6.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (2.8.0+cpu)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (2.1.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (4.67.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from peft==0.17.1) (25.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from peft==0.17.1) (1.10.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (4.15.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2024.6.1)\n",
            "Requirement already satisfied: requests in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2.32.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.13.0->peft==0.17.1) (3.1.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.13.0->peft==0.17.1) (3.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.13.0->peft==0.17.1) (1.13.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->peft==0.17.1) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers->peft==0.17.1) (2025.9.1)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers->peft==0.17.1) (0.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.17.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.17.1) (2.1.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "üöÄ Instalando dependencias adicionales...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.10.1)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.35.0)\n",
            "Requirement already satisfied: safetensors in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (2.8.0+cpu)\n",
            "Requirement already satisfied: psutil in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (2.1.2)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: requests in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\anfep\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚ú® ¬°Instalaci√≥n completada!\n",
            "\n",
            "üîç Verificando instalaciones...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "c:\\Users\\anfep\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Verificaci√≥n exitosa:\n",
            "   PyTorch: 2.8.0+cpu\n",
            "   Transformers: 4.56.1\n",
            "   Datasets: 4.0.0\n",
            "   PEFT: 0.17.1\n",
            "\n",
            "üéâ ¬°Todo listo para hacer fine-tuning!\n"
          ]
        }
      ],
      "source": [
        "# Opci√≥n 1: Instalaci√≥n paso a paso con comandos m√°gicos\n",
        "print(\"üöÄ Instalando PyTorch...\")\n",
        "%pip install torch==2.8.0+cpu torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "print(\"üöÄ Instalando Transformers...\")\n",
        "%pip install transformers==4.56.1\n",
        "\n",
        "print(\"üöÄ Instalando Datasets...\")\n",
        "%pip install datasets==4.0.0\n",
        "\n",
        "print(\"üöÄ Instalando Evaluate...\")\n",
        "%pip install evaluate==0.4.5\n",
        "\n",
        "print(\"üöÄ Instalando ROUGE Score...\")\n",
        "%pip install rouge_score==0.1.2\n",
        "\n",
        "print(\"üöÄ Instalando PEFT...\")\n",
        "%pip install peft==0.17.1\n",
        "\n",
        "print(\"üöÄ Instalando dependencias adicionales...\")\n",
        "%pip install accelerate huggingface_hub safetensors\n",
        "\n",
        "print(\"‚ú® ¬°Instalaci√≥n completada!\")\n",
        "\n",
        "# Verificar instalaciones\n",
        "print(\"\\nüîç Verificando instalaciones...\")\n",
        "try:\n",
        "    import torch\n",
        "    import transformers\n",
        "    import datasets\n",
        "    import evaluate\n",
        "    import peft\n",
        "    \n",
        "    print(\"‚úÖ Verificaci√≥n exitosa:\")\n",
        "    print(f\"   PyTorch: {torch.__version__}\")\n",
        "    print(f\"   Transformers: {transformers.__version__}\")\n",
        "    print(f\"   Datasets: {datasets.__version__}\")\n",
        "    print(f\"   PEFT: {peft.__version__}\")\n",
        "    print(\"\\nüéâ ¬°Todo listo para hacer fine-tuning!\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Error en la verificaci√≥n: {e}\")\n",
        "    print(\"Puede que necesites reiniciar el kernel del notebook.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.8.0+cpu\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
            "Required-by: accelerate, peft, torchaudio, torchvision\n",
            "---\n",
            "Name: transformers\n",
            "Version: 4.56.1\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft\n",
            "---\n",
            "Name: datasets\n",
            "Version: 4.0.0\n",
            "Summary: HuggingFace community-driven open-source library of datasets\n",
            "Home-page: https://github.com/huggingface/datasets\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: thomas@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
            "Requires: dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, tqdm, xxhash\n",
            "Required-by: evaluate\n",
            "---\n",
            "Name: evaluate\n",
            "Version: 0.4.5\n",
            "Summary: HuggingFace community-driven open-source library of evaluation\n",
            "Home-page: https://github.com/huggingface/evaluate\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: leandro@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
            "Requires: datasets, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, requests, tqdm, xxhash\n",
            "Required-by: \n",
            "---\n",
            "Name: rouge-score\n",
            "Version: 0.1.2\n",
            "Summary: Pure python implementation of ROUGE-1.5.5.\n",
            "Home-page: https://github.com/google-research/google-research/tree/master/rouge\n",
            "Author: Google LLC\n",
            "Author-email: rouge-opensource@google.com\n",
            "License: \n",
            "Location: c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
            "Requires: absl-py, nltk, numpy, six\n",
            "Required-by: \n",
            "---\n",
            "Name: peft\n",
            "Version: 0.17.1\n",
            "Summary: Parameter-Efficient Fine-Tuning (PEFT)\n",
            "Home-page: https://github.com/huggingface/peft\n",
            "Author: The HuggingFace team\n",
            "Author-email: benjamin@huggingface.co\n",
            "License: Apache\n",
            "Location: c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
            "Requires: accelerate, huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch, tqdm, transformers\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Package(s) not found: loralib, torchdata\n"
          ]
        }
      ],
      "source": [
        "%pip show torch torchdata transformers datasets evaluate rouge_score loralib peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ T5 funciona: Hallo Welt\n"
          ]
        }
      ],
      "source": [
        "# verificar que transformers funciona\n",
        "\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Probar con el modelo m√°s peque√±o\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Test b√°sico\n",
        "input_text = \"translate English to Spanish: Hello world\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "outputs = model.generate(input_ids, max_length=20)\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(f\"‚úÖ T5 funciona: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV0mclXEV7aV"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "### 1.1 - Set up Kernel and Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pFVij_p3V7aX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Importe los componentes necesarios.\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtIOTMkrV7aX",
        "tags": []
      },
      "source": [
        "<a name='1.2'></a>\n",
        "### 1.2 - Cargar Dataset y LLM\n",
        "\n",
        "[PubMed Summarization](https://huggingface.co/datasets/ccdv/pubmed-summarization) es un dataset de Hugging Face que contiene art√≠culos cient√≠ficos m√©dicos de PubMed con sus correspondientes res√∫menes (abstracts). Este dataset contiene m√°s de 133,000 art√≠culos m√©dicos y es ideal para entrenar modelos de resumen especializados en terminolog√≠a m√©dica y cient√≠fica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hf_xet in c:\\users\\anfep\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.10)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "52e88adfc6324f06a2957699938e349f",
            "1c727073a23e4c29a685221fc2c8297d",
            "20e73a01ed92416f9111b87ea630c1ec",
            "d137e6f6e7d14bd68b13c9ffff7444b6",
            "8e35b400ff644bd4af0079392a461000",
            "7af87c4f3c0f4ad7ad90c5b835743f8c",
            "",
            "848d8e40c254442b8cc93c64c7176dcd"
          ]
        },
        "id": "hmH9Or7RV7aY",
        "outputId": "610d1c04-7334-4417-d894-75b0c3828f0a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splits disponibles: ['train', 'validation', 'test']\n"
          ]
        }
      ],
      "source": [
        "#dataset = load_dataset(\"knkarthick/dialogsum\")\n",
        "dataset = load_dataset(\"ccdv/pubmed-summarization\")\n",
        "print(f\"Splits disponibles: {list(dataset.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ESTRUCTURA DEL DATASET:\n",
            "{'article': Value('string'), 'abstract': Value('string')}\n",
            "\n",
            "TAMA√ëOS DE LOS SPLITS:\n",
            "  train: 119,924\n",
            "  validation: 6,633\n",
            "  test: 6,658\n",
            "\n",
            "EJEMPLO DEL DATASET:\n",
            "Art√≠culo (primeros 300 chars):\n",
            "a recent systematic analysis showed that in 2011 , 314 ( 296 - 331 ) million children younger than 5 years were mildly , moderately or severely stunted and 258 ( 240 - 274 ) million were mildly , moderately or severely underweight in the developing countries . \n",
            " in iran a study among 752 high school...\n",
            "\n",
            "Resumen (Abstract):\n",
            "background : the present study was carried out to assess the effects of community nutrition intervention based on advocacy approach on malnutrition status among school - aged children in shiraz , iran.materials and methods : this case - control nutritional intervention has been done between 2008 and 2009 on 2897 primary and secondary school boys and girls ( 7 - 13 years old ) based on advocacy approach in shiraz , iran . \n",
            " the project provided nutritious snacks in public schools over a 2-year period along with advocacy oriented actions in order to implement and promote nutritional intervention . for evaluation of effectiveness of the intervention growth monitoring indices of pre- and post - intervention were statistically compared.results:the frequency of subjects with body mass index lower than 5% decreased significantly after intervention among girls ( p = 0.02 ) . \n",
            " however , there were no significant changes among boys or total population . \n",
            " the mean of all anthropometric indices changed significantly after intervention both among girls and boys as well as in total population . \n",
            " the pre- and post - test education assessment in both groups showed that the student 's average knowledge score has been significantly increased from 12.5  3.2 to 16.8  4.3 ( p < 0.0001).conclusion : this study demonstrates the potential success and scalability of school feeding programs in iran . \n",
            " community nutrition intervention based on the advocacy process model is effective on reducing the prevalence of underweight specifically among female school aged children .\n",
            "\n",
            "Longitudes:\n",
            "  Art√≠culo: 28460 caracteres\n",
            "  Resumen: 1575 caracteres\n"
          ]
        }
      ],
      "source": [
        "print(\"ESTRUCTURA DEL DATASET:\")\n",
        "print(dataset[\"train\"].features)\n",
        "\n",
        "print(f\"\\nTAMA√ëOS DE LOS SPLITS:\")\n",
        "for split_name in dataset.keys():\n",
        "    print(f\"  {split_name}: {len(dataset[split_name]):,}\")\n",
        "\n",
        "print(\"\\nEJEMPLO DEL DATASET:\")\n",
        "example = dataset[\"train\"][0]\n",
        "print(f\"Art√≠culo (primeros 300 chars):\\n{example['article'][:300]}...\\n\")\n",
        "print(f\"Resumen (Abstract):\\n{example['abstract']}\")\n",
        "print(f\"\\nLongitudes:\")\n",
        "print(f\"  Art√≠culo: {len(example['article'])} caracteres\")\n",
        "print(f\"  Resumen: {len(example['abstract'])} caracteres\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBsjjW4OV7aY",
        "tags": []
      },
      "source": [
        "Load the pre-trained [FLAN-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5) and its tokenizer directly from HuggingFace. Notice that you will be using the [small version](https://huggingface.co/google/flan-t5-base) of FLAN-T5. Setting `torch_dtype=torch.bfloat16` specifies the memory type to be used by this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "681aacbb846341d68528367bf1e6ea5e",
            "4e0a9c5d95cb4edf87322c51dc4b6ad7",
            "055404322df7485a9276138114ecb109",
            "5200456208324ff5b5daafd329e11a67",
            "e8fe83c03ef94d50a02233c5c4776e14",
            "ab65d51105de4aac840a2f3a27291ffb",
            "2e0dbf02a6fc4deab0e7b59375fcd9a2"
          ]
        },
        "id": "SsEMZw1CV7aY",
        "outputId": "89265c6d-4e74-486e-8c76-c73a7a9a174a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Cargamos el modelo y el tokenizador\n",
        "\n",
        "model_name='google/flan-t5-base'\n",
        "# model_name='t5-base'\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbNtotpbV7aZ",
        "tags": []
      },
      "source": [
        "<a name='1.3'></a>\n",
        "### 1.3 - Prueba del modelo con Zero Shot Inferencing\n",
        "\n",
        "Pruebe el modelo con la inferencia de tiro cero. Puede ver que el modelo tiene dificultades para resumir el di√°logo en comparaci√≥n con el resumen de referencia, pero extrae informaci√≥n importante del texto que indica que el modelo se puede ajustar a la tarea en cuesti√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ruNKVIGEV7aZ",
        "outputId": "25596b54-9780-47a5-83eb-80ec09e2d111",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "ART√çCULO M√âDICO (PREVIEW):\n",
            "determinar a presena de anticorpos ige especficos para superantgenos estafiloccicos e o grau de sensibilizao mediada por esses , assim como se esses esto associados  gravidade da asma em pacientes adultos . \n",
            " estudo transversal incluindo asmticos adultos em acompanhamento ambulatorial em um hospital universitrio tercirio no rio de janeiro ( rj ) . \n",
            " os pacientes foram alocados consecutivamente em dois grupos de gravidade da asma segundo critrios da global initiative for asthma : asma leve ( al )...\n",
            "----------------------------------------------------------------------------------------------------\n",
            "RESUMEN HUMANO (BASELINE):\n",
            "abstractobjective : to determine the presence of staphylococcal superantigen - specific ige antibodies and degree of ige - mediated sensitization , as well as whether or not those are associated with the severity of asthma in adult patients . \n",
            " methods : this was a cross - sectional study involving outpatients with asthma under treatment at a tertiary care university hospital in the city of rio de janeiro , brazil . \n",
            " consecutive patients were divided into two groups according to the severity of asthma based on the global initiative for asthma criteria : mild asthma ( ma ) , comprising patients with mild intermittent or persistent asthma ; and moderate or severe asthma ( msa ) . \n",
            " we determined the serum levels of staphylococcal toxin - specific ige antibodies , comparing the results and performing a statistical analysis . \n",
            " results : the study included 142 patients : 72 in the ma group ( median age = 46 years ; 59 females ) and 70 in the msa group ( median age = 56 years ; 60 females ) . in the sample as a whole , 62 patients ( 43.7% ) presented positive results for staphylococcal toxin - specific ige antibodies : staphylococcal enterotoxin a ( sea ) , in 29 ( 20.4% ) ; seb , in 35 ( 24.6% ) ; sec , in 33 ( 23.2% ) ; and toxic shock syndrome toxin ( tsst ) , in 45 ( 31.7% ) . \n",
            " the mean serum levels of ige antibodies to sea , seb , sec , and tsst were 0.96 u / l , 1.09 u / l , 1.21 u / l , and 1.18 u / l , respectively . \n",
            " there were no statistically significant differences between the two groups in terms of the qualitative or quantitative results . \n",
            " conclusions : serum ige antibodies to sea , seb , sec , and tsst were detected in 43.7% of the patients in our sample . \n",
            " however , neither the qualitative nor quantitative results showed a statistically significant association with the clinical severity of asthma .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "RESUMEN GENERADO CON ZERO SHOT:\n",
            "essas estudo transversal en asocia√ßo ambulatorio a un hospital terrio terrio terrio terrio terrio terrio terrio terrio terrio terrio terrio terrio terrio terrio\n"
          ]
        }
      ],
      "source": [
        "index = 5\n",
        "\n",
        "article = dataset['test'][index]['article']\n",
        "summary = dataset['test'][index]['abstract']\n",
        "\n",
        "# Truncar art√≠culo para visualizaci√≥n\n",
        "article_preview = article[:500] + \"...\" if len(article) > 500 else article\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following medical research article.\n",
        "\n",
        "{article_preview}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt', max_length=512, truncation=True)\n",
        "output = tokenizer.decode(\n",
        "    original_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=100,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-' * 100\n",
        "print(dash_line)\n",
        "print(f'ART√çCULO M√âDICO (PREVIEW):\\n{article_preview}')\n",
        "print(dash_line)\n",
        "print(f'RESUMEN HUMANO (BASELINE):\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'RESUMEN GENERADO CON ZERO SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Realizar Full Fine-Tuning para Res√∫menes M√©dicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7EhKQABV7aZ",
        "tags": []
      },
      "source": [
        "<a name='2.1'></a>\n",
        "### 2.1 - Preprocesar el dataset de Art√≠culos M√©dicos\n",
        "\n",
        "Se necesita convertir los pares art√≠culo-resumen en instrucciones expl√≠citas para el LLM. Agregar una instrucci√≥n al inicio del art√≠culo como `Summarize the following medical research article` y al final agregar `Summary:` como se muestra a continuaci√≥n:\n",
        "\n",
        "Training prompt (article):\n",
        "Summarize the following medical research article.\n",
        "Background: Diabetes mellitus is a chronic metabolic disorder characterized by hyperglycemia resulting from defects in insulin secretion, insulin action, or both...\n",
        "Summary:\n",
        "\n",
        "Training response (abstract):\n",
        "\n",
        "This study investigates the relationship between diabetes and cardiovascular complications in a cohort of 500 patients over 5 years.\n",
        "\n",
        "\n",
        "Luego preprocesar el dataset prompt-respuesta en tokens y extraer sus `input_ids` (1 por token)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando tokenizaci√≥n del dataset m√©dico...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:   0%|          | 0/6658 [00:00<?, ? examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of prompt list:  1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:  15%|‚ñà‚ñå        | 1000/6658 [00:00<00:01, 3794.40 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of prompt list:  1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:  30%|‚ñà‚ñà‚ñà       | 2000/6658 [00:00<00:01, 3898.69 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of prompt list:  1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 3000/6658 [00:00<00:00, 3901.91 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of prompt list:  1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 4000/6658 [00:01<00:00, 3906.29 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of prompt list:  1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 5000/6658 [00:01<00:00, 3917.14 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of prompt list:  1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 6000/6658 [00:01<00:00, 3839.02 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of prompt list:  658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6658/6658 [00:01<00:00, 3506.29 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizaci√≥n completada\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 119924\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 6633\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 6658\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def tokenize_function(example):\n",
        "    start_prompt = 'Summarize the following medical research article.\\n\\n'\n",
        "    end_prompt = '\\n\\nSummary: '\n",
        "    \n",
        "    # Truncar art√≠culos muy largos\n",
        "    max_article_length = 500  # caracteres\n",
        "    \n",
        "    prompt = []\n",
        "    for article in example[\"article\"]:\n",
        "        # Truncar art√≠culo \n",
        "        truncated_article = article[:max_article_length] + \"...\" if len(article) > max_article_length else article\n",
        "        full_prompt = start_prompt + truncated_article + end_prompt\n",
        "        prompt.append(full_prompt)\n",
        "    \n",
        "    print(\"Size of prompt list: \", len(prompt))\n",
        "    \n",
        "    # Tokenizar \n",
        "    example['input_ids'] = tokenizer(\n",
        "        prompt, \n",
        "        padding=\"max_length\", \n",
        "        truncation=True, \n",
        "        max_length=512, \n",
        "        return_tensors=\"pt\"\n",
        "    ).input_ids\n",
        "    \n",
        "    example['labels'] = tokenizer(\n",
        "        example[\"abstract\"], \n",
        "        padding=\"max_length\", \n",
        "        truncation=True, \n",
        "        max_length=150,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_ids\n",
        "\n",
        "    return example\n",
        "\n",
        "print(\"Iniciando tokenizaci√≥n del dataset m√©dico...\")\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['article', 'abstract'])\n",
        "\n",
        "print(\"Tokenizaci√≥n completada\")\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VERIFICANDO TOKENIZACI√ìN:\n",
            "Tipo de dataset: <class 'datasets.dataset_dict.DatasetDict'>\n",
            "\n",
            "Primer ejemplo tokenizado:\n",
            "Dataset({\n",
            "    features: ['input_ids', 'labels'],\n",
            "    num_rows: 1\n",
            "})\n",
            "\n",
            "Tipo de input_ids: <class 'list'>\n",
            "Tipo de labels: <class 'list'>\n",
            "Forma de input_ids: torch.Size([512])\n",
            "Forma de labels: torch.Size([150])\n",
            "\n",
            "Input decodificado (primeros 300 chars):\n",
            "Summarize the following medical research article. a recent systematic analysis showed that in 2011 , 314 ( 296 - 331 ) million children younger than 5 years were mildly , moderately or severely stunted and 258 ( 240 - 274 ) million were mildly , moderately or severely underweight in the developing c...\n",
            "\n",
            "Label decodificado:\n",
            "background : the present study was carried out to assess the effects of community nutrition intervention based on advocacy approach on malnutrition status among school - aged children in shiraz , iran.materials and methods : this case - control nutritional intervention has been done between 2008 and 2009 on 2897 primary and secondary school boys and girls ( 7 - 13 years old ) based on advocacy approach in shiraz , iran . the project provided nutritious snacks in public schools over a 2-year period along with advocacy oriented actions in order to implement and promote nutritional intervention . for evaluation of effectiveness of the intervention growth monitoring indices of pre- and post - intervention were\n",
            "\n",
            "ESTAD√çSTICAS:\n",
            "  Longitud de input_ids: 512\n",
            "  Longitud de labels: 150\n",
            "  Tokens no-padding en input: 144\n",
            "  Tokens no-padding en labels: 150\n"
          ]
        }
      ],
      "source": [
        "print(\"VERIFICANDO TOKENIZACI√ìN:\")\n",
        "print(f\"Tipo de dataset: {type(tokenized_datasets)}\")\n",
        "\n",
        "first_example = tokenized_datasets[\"train\"].select([0])\n",
        "print(f\"\\nPrimer ejemplo tokenizado:\")\n",
        "print(first_example)\n",
        "\n",
        "input_ids = first_example['input_ids'][0]\n",
        "labels = first_example['labels'][0]\n",
        "\n",
        "print(f\"\\nTipo de input_ids: {type(input_ids)}\")\n",
        "print(f\"Tipo de labels: {type(labels)}\")\n",
        "\n",
        "if isinstance(input_ids, list):\n",
        "    import torch\n",
        "    input_ids_tensor = torch.tensor(input_ids)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "    print(f\"Forma de input_ids: {input_ids_tensor.shape}\")\n",
        "    print(f\"Forma de labels: {labels_tensor.shape}\")\n",
        "else:\n",
        "    print(f\"Forma de input_ids: {input_ids.shape}\")\n",
        "    print(f\"Forma de labels: {labels.shape}\")\n",
        "\n",
        "# Decodificar para verificar (usar los primeros elementos si es una lista)\n",
        "if isinstance(input_ids, list):\n",
        "    sample_input = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "    sample_label = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "else:\n",
        "    sample_input = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "    sample_label = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "\n",
        "print(f\"\\nInput decodificado (primeros 300 chars):\\n{sample_input[:300]}...\")\n",
        "print(f\"\\nLabel decodificado:\\n{sample_label}\")\n",
        "\n",
        "# Verificar longitudes\n",
        "print(f\"\\nESTAD√çSTICAS:\")\n",
        "print(f\"  Longitud de input_ids: {len(input_ids)}\")\n",
        "print(f\"  Longitud de labels: {len(labels)}\")\n",
        "print(f\"  Tokens no-padding en input: {sum(1 for x in input_ids if x != tokenizer.pad_token_id)}\")\n",
        "print(f\"  Tokens no-padding en labels: {sum(1 for x in labels if x != tokenizer.pad_token_id)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: 119924 ‚Üí 502 ejemplos\n",
            "validation: 6633 ‚Üí 511 ejemplos\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6658/6658 [00:01<00:00, 6558.14 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: 6658 ‚Üí 513 ejemplos\n",
            "\n",
            "TAMA√ëOS FINALES:\n",
            "  Training: (502, 2)\n",
            "  Validation: (511, 2)\n",
            "  Test: (513, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def smart_subsample(dataset, min_examples=50, max_examples=500):\n",
        "    \"\"\"Submuestrea manteniendo un m√≠nimo de ejemplos √∫tiles\"\"\"\n",
        "    total_size = len(dataset)\n",
        "    \n",
        "    if total_size <= min_examples:\n",
        "        return dataset\n",
        "    elif total_size <= max_examples:\n",
        "        step = max(2, total_size // (min_examples * 2))\n",
        "        return dataset.filter(lambda example, index: index % step == 0, with_indices=True)\n",
        "    else:\n",
        "        step = total_size // max_examples\n",
        "        return dataset.filter(lambda example, index: index % step == 0, with_indices=True)\n",
        "\n",
        "for split in tokenized_datasets.keys():\n",
        "    original_size = len(tokenized_datasets[split])\n",
        "    tokenized_datasets[split] = smart_subsample(tokenized_datasets[split])\n",
        "    new_size = len(tokenized_datasets[split])\n",
        "    print(f\"{split}: {original_size} ‚Üí {new_size} ejemplos\")\n",
        "\n",
        "print(f\"\\nTAMA√ëOS FINALES:\")\n",
        "print(f\"  Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"  Validation: {tokenized_datasets['validation'].shape}\")  \n",
        "print(f\"  Test: {tokenized_datasets['test'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg2hlvGiV7aa"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "### 2.2 - Aplicar Fine-Tuning para el modelo con el dataset de Art√≠culos M√©dicos\n",
        "\n",
        "Ahora utilice la clase integrada \"Trainer\" de Hugging Face (consulte la documentaci√≥n [aqu√≠](https://huggingface.co/docs/transformers/main_classes/trainer)). Pase el conjunto de datos preprocesado de art√≠culos m√©dicos con referencia al modelo original. Los par√°metros de entrenamiento est√°n configurados espec√≠ficamente para la tarea de resumen m√©dico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YnVXOApPV7aa",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuraci√≥n de entrenamiento lista para res√∫menes m√©dicos\n",
            "Datos de entrenamiento: 502 ejemplos\n",
            "Datos de validaci√≥n: 511 ejemplos\n"
          ]
        }
      ],
      "source": [
        "output_dir = f'./medical-summarization-training-{str(int(time.time()))}'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    max_steps=100,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    per_device_train_batch_size=4, \n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=original_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation']\n",
        ")\n",
        "\n",
        "print(\"Configuraci√≥n de entrenamiento lista para res√∫menes m√©dicos\")\n",
        "print(f\"Datos de entrenamiento: {len(tokenized_datasets['train'])} ejemplos\")\n",
        "print(f\"Datos de validaci√≥n: {len(tokenized_datasets['validation'])} ejemplos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKNYWu0uV7ab",
        "tags": []
      },
      "source": [
        "Start training process...\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5Zb3UgY2FuIHNhZmVseSBpZ25vcmUgdGhlIHdhcm5pbmcgbWVzc2FnZXMuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xL-BFJRiV7ab",
        "outputId": "a74dce74-d748-4dbb-edf5-c23128bec758",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#trainer.train()\n",
        "#Entrenar una versi√≥n completamente tuneada  del modelo toma  horas en una GPU. Para ahorrar tiempo, se puede descargar un punto de control del modelo completamente ajustado para utilizarlo en el resto del notebook The size of the downloaded instruct model is approximately 1GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4gDo7HUV7ac",
        "tags": []
      },
      "source": [
        "Create an instance of the `AutoModelForSeq2SeqLM` class for the instruct model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkapq1TaV7ab"
      },
      "source": [
        "Entrenar una versi√≥n completamente tuneada  del modelo toma  horas en una GPU. Para ahorrar tiempo, se puede descargar un punto de control del modelo completamente ajustado para utilizarlo en el resto del notebook The size of the downloaded instruct model is approximately 1GB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo 'fine-tuneado'\n"
          ]
        }
      ],
      "source": [
        "instruct_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base', torch_dtype=torch.bfloat16)\n",
        "\n",
        "print(\"Modelo 'fine-tuneado'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U0x74Z2ZV7ac",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.models.t5.modeling_t5.T5ForConditionalGeneration"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "type(instruct_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHeExNydV7am"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "### 2.3 - Evaluar el modelo cualitativamente (evaluaci√≥n humana)\n",
        "\n",
        "Como ocurre con muchas aplicaciones GenAI, un enfoque cualitativo en el que uno se hace la pregunta \"¬øMi modelo se comporta como se supone que debe hacerlo\" suele ser un buen punto de partida. En el siguiente ejemplo, puede ver c√≥mo el modelo ajustado deber√≠a ser capaz de crear res√∫menes m√°s precisos y espec√≠ficos de art√≠culos m√©dicos en comparaci√≥n con la capacidad limitada del modelo original para comprender terminolog√≠a m√©dica especializada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oqUEQycEV7an",
        "outputId": "5883195b-08ad-4bf9-b56c-0561b0210f9b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "ART√çCULO M√âDICO (MUESTRA):\n",
            "radiocontrast - induced nephropathy ( rin ) can lead to acute renal failure ( arf ) , which may require dialysis therapy . \n",
            " arf increases treatment cost due to sepsis , hemorrhage , respiratory failure , and a long hospitalization.[13 ] rin is an important cause of hospital - acquired arf and is responsible for 12% of cases . \n",
            " renal medullary hypoxia and the direct toxic effects of iodinated con...\n",
            "----------------------------------------------------------------------------------------------------\n",
            "RESUMEN HUMANO (BASELINE):\n",
            "radiocontrast administration is an important cause of acute renal failure . in this study , \n",
            " compared the plasma creatinine levels with spot urine il-18 levels following radiocontrast administration . \n",
            " twenty patients ( 11 males , 9 females ) underwent radiocontrast diagnostic and therapeutic - enhanced examinations . \n",
            " the rin mehran risk score was low ( 5 ) . \n",
            " the radiocontrast agents used were 623 mg / ml iopromid ( 1.5 ml / kg ) , and 100 ml of 650 mg / ml meglumine diatrizoate as three - way oral and rectal contrast material for abdominal computed tomography ( ct ) scans . \n",
            " serum blood urea nitrogen , creatinine , na , k , cl , ca , p , creatinine clearance , and spot urine il-18 levels were analyzed before and repeated at 24 , 48 , and 72 h after radiocontrast administration . \n",
            " six and 24-h urinary il-18 levels were measured with a human il-18 elisa kit following radiocontrast administration . \n",
            " an increase in plasma creatinine 24 and 48 h following radiocontrast administration was observed compared with precontrast values , but it was not statistically significant ( p=0.052 and p=0.285 , respectively ) . a statistically significant increase in il-18 levels was observed at 6 and 24 h , compared with precontrast values ( p=0.048 and p=0.028 , respectively ) . \n",
            " a tendency for postcontrast 24-h urinary il-18 levels to increase was observed compared with 6 h , but the increase was not statistically significant ( p=0.808 ) . \n",
            " our results show that plasma creatinine starts to increase at 24th hour ; however , spot urine il-18 levels go up at 6th hour following radiocontrast administration implying urine il-18 to be an earlier parameter for kidney injury .\n",
            "----------------------------------------------------------------------------------------------------\n",
            "MODELO ORIGINAL:\n",
            "Radiocontrast nephropathy is a risk factor for hospital-acquired arf.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "MODELO CON FINE-TUNING:\n",
            "Radiocontrast nephropathy is a risk factor for hospital-acquired arf.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "AN√ÅLISIS DE CALIDAD:\n",
            "Modelo Original:\n",
            "  Longitud: 9 palabras\n",
            "  T√©rminos m√©dicos: 0\n",
            "  Similitud con referencia: 0.556\n",
            "Modelo Fine-tuned:\n",
            "  Longitud: 9 palabras\n",
            "  T√©rminos m√©dicos: 0\n",
            "  Similitud con referencia: 0.556\n"
          ]
        }
      ],
      "source": [
        "index = 25\n",
        "article = dataset['test'][index]['article']\n",
        "human_baseline_summary = dataset['test'][index]['abstract']\n",
        "\n",
        "article_for_model = article[:1000] + \"...\" if len(article) > 1000 else article\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following medical research article.\n",
        "\n",
        "{article_for_model}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "\n",
        "original_model_outputs = original_model.generate(\n",
        "    input_ids=input_ids, \n",
        "    generation_config=GenerationConfig(max_new_tokens=120, num_beams=1)\n",
        ")\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(\n",
        "    input_ids=input_ids, \n",
        "    generation_config=GenerationConfig(max_new_tokens=120, num_beams=1)\n",
        ")\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "dash_line = '-' * 100\n",
        "print(dash_line)\n",
        "print(f'ART√çCULO M√âDICO (MUESTRA):')\n",
        "print(f'{article_for_model[:400]}...')\n",
        "print(dash_line)\n",
        "print(f'RESUMEN HUMANO (BASELINE):\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'MODELO ORIGINAL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'MODELO CON FINE-TUNING:\\n{instruct_model_text_output}')\n",
        "print(dash_line)\n",
        "\n",
        "def analyze_medical_summary(summary, reference):\n",
        "    \"\"\"Analiza la calidad del resumen m√©dico\"\"\"\n",
        "    summary_words = set(summary.lower().split())\n",
        "    reference_words = set(reference.lower().split())\n",
        "    \n",
        "    medical_terms = {'patient', 'treatment', 'study', 'clinical', 'therapy', 'disease', 'diagnosis', 'medical', 'health', 'hospital', 'doctor', 'medicine'}\n",
        "    \n",
        "    summary_medical = len(summary_words.intersection(medical_terms))\n",
        "    reference_medical = len(reference_words.intersection(medical_terms))\n",
        "    \n",
        "    overlap = len(summary_words.intersection(reference_words))\n",
        "    \n",
        "    return {\n",
        "        'length': len(summary.split()),\n",
        "        'medical_terms': summary_medical,\n",
        "        'word_overlap': overlap,\n",
        "        'similarity_score': overlap / max(len(summary_words), 1)\n",
        "    }\n",
        "\n",
        "print(f\"\\nAN√ÅLISIS DE CALIDAD:\")\n",
        "orig_analysis = analyze_medical_summary(original_model_text_output, human_baseline_summary)\n",
        "inst_analysis = analyze_medical_summary(instruct_model_text_output, human_baseline_summary)\n",
        "\n",
        "print(f\"Modelo Original:\")\n",
        "print(f\"  Longitud: {orig_analysis['length']} palabras\")\n",
        "print(f\"  T√©rminos m√©dicos: {orig_analysis['medical_terms']}\")\n",
        "print(f\"  Similitud con referencia: {orig_analysis['similarity_score']:.3f}\")\n",
        "\n",
        "print(f\"Modelo Fine-tuned:\")\n",
        "print(f\"  Longitud: {inst_analysis['length']} palabras\")\n",
        "print(f\"  T√©rminos m√©dicos: {inst_analysis['medical_terms']}\")\n",
        "print(f\"  Similitud con referencia: {inst_analysis['similarity_score']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nVduwEAV7an"
      },
      "source": [
        "<a name='2.4'></a>\n",
        "### 2.4 - Evaluar el modelo cuantitativamente (con m√©tricas ROUGE)\n",
        "\n",
        "La m√©trica [ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)) ayuda a cuantificar la validez de los res√∫menes generados por los modelos al compararlos con res√∫menes de referencia creados por expertos m√©dicos. Para art√≠culos m√©dicos, ROUGE es especialmente √∫til porque mide la preservaci√≥n de informaci√≥n clave y terminolog√≠a especializada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "38179e06d5d640dbae6c746bd4eae68f"
          ]
        },
        "id": "qau_WJrhV7an",
        "outputId": "a16372aa-e307-492e-9028-1368313b1aa8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqXw8-QV7an"
      },
      "source": [
        "Genere las salidas para la muestra del conjunto de datos de prueba (solo 10 di√°logos y res√∫menes para ahorrar tiempo) y guarde los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wbLNwQHAV7an",
        "outputId": "6376f430-81aa-42eb-e533-f7c773768b1d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generando res√∫menes de art√≠culos m√©dicos para evaluaci√≥n...\n",
            "Procesado art√≠culo m√©dico 1/10\n",
            "Procesado art√≠culo m√©dico 2/10\n",
            "Procesado art√≠culo m√©dico 3/10\n",
            "Procesado art√≠culo m√©dico 4/10\n",
            "Procesado art√≠culo m√©dico 5/10\n",
            "Procesado art√≠culo m√©dico 6/10\n",
            "Procesado art√≠culo m√©dico 7/10\n",
            "Procesado art√≠culo m√©dico 8/10\n",
            "Procesado art√≠culo m√©dico 9/10\n",
            "Procesado art√≠culo m√©dico 10/10\n",
            "\n",
            "PRIMEROS 3 EJEMPLOS DE RES√öMENES M√âDICOS:\n",
            "\n",
            "--- ART√çCULO M√âDICO 1 ---\n",
            "Humano (Abstract): research on the implications of anxiety in parkinson 's disease ( pd ) has been neglected despite its prevalence in nearly 50% of patients and its neg...\n",
            "Original: anxiety and depression are common in pd patients...\n",
            "Fine-tuned: anxiety and depression are common in pd patients...\n",
            "\n",
            "--- ART√çCULO M√âDICO 2 ---\n",
            "Humano (Abstract): small non - coding rnas include sirna , mirna , pirna and snorna . \n",
            " the involvement of mirnas in the regulation of mammary gland tumorigenesis has be...\n",
            "Original: Micrornas are small non - coding rnas that regulate the stability or translational efficiency of targeted messenger rnas....\n",
            "Fine-tuned: Micrornas are small non - coding rnas that regulate the stability or translational efficiency of targeted messenger rnas....\n",
            "\n",
            "--- ART√çCULO M√âDICO 3 ---\n",
            "Humano (Abstract): objective : to evaluate the efficacy and safety of outpatient management of severe ovarian hyperstimulation syndrome  ( ohss ) requiring placement of ...\n",
            "Original: ohss is a complication of ovulation induction. vascular endothelial growth factor is a potent stimulator of the vascular endothelium and appears to pl...\n",
            "Fine-tuned: ohss is a complication of ovulation induction. vascular endothelial growth factor is a potent stimulator of the vascular endothelium and appears to pl...\n",
            "\n",
            "DataFrame completo con 10 res√∫menes m√©dicos:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>research on the implications of anxiety in par...</td>\n",
              "      <td>anxiety and depression are common in pd patients</td>\n",
              "      <td>anxiety and depression are common in pd patients</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>small non - coding rnas include sirna , mirna ...</td>\n",
              "      <td>Micrornas are small non - coding rnas that reg...</td>\n",
              "      <td>Micrornas are small non - coding rnas that reg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>objective : to evaluate the efficacy and safet...</td>\n",
              "      <td>ohss is a complication of ovulation induction....</td>\n",
              "      <td>ohss is a complication of ovulation induction....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>congenital adrenal hyperplasia is a group of a...</td>\n",
              "      <td>Congenital adrenal hyperplasia is a group of a...</td>\n",
              "      <td>Congenital adrenal hyperplasia is a group of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>objective(s):pentoxifylline is an immunomodula...</td>\n",
              "      <td>Type 1 diabetes is a autoimmune disease charac...</td>\n",
              "      <td>Type 1 diabetes is a autoimmune disease charac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>abstractobjective : to determine the presence ...</td>\n",
              "      <td>A transversal study of asma gravidade in adult...</td>\n",
              "      <td>A transversal study of asma gravidade in adult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>background : since the family is a social syst...</td>\n",
              "      <td>Stress in the family is a source of stress for...</td>\n",
              "      <td>Stress in the family is a source of stress for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>background and objective :   anxiety and depre...</td>\n",
              "      <td>Increasing number of cardiovascular diseases i...</td>\n",
              "      <td>Increasing number of cardiovascular diseases i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>worldwide emergence of variant viruses has pro...</td>\n",
              "      <td>nepali nephritid patients are screened for inf...</td>\n",
              "      <td>nepali nephritid patients are screened for inf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>excess weight has generally been associated wi...</td>\n",
              "      <td>Obesity is becoming a worldwide phenomenon and...</td>\n",
              "      <td>Obesity is becoming a worldwide phenomenon and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  research on the implications of anxiety in par...   \n",
              "1  small non - coding rnas include sirna , mirna ...   \n",
              "2  objective : to evaluate the efficacy and safet...   \n",
              "3  congenital adrenal hyperplasia is a group of a...   \n",
              "4  objective(s):pentoxifylline is an immunomodula...   \n",
              "5  abstractobjective : to determine the presence ...   \n",
              "6  background : since the family is a social syst...   \n",
              "7  background and objective :   anxiety and depre...   \n",
              "8  worldwide emergence of variant viruses has pro...   \n",
              "9  excess weight has generally been associated wi...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0   anxiety and depression are common in pd patients   \n",
              "1  Micrornas are small non - coding rnas that reg...   \n",
              "2  ohss is a complication of ovulation induction....   \n",
              "3  Congenital adrenal hyperplasia is a group of a...   \n",
              "4  Type 1 diabetes is a autoimmune disease charac...   \n",
              "5  A transversal study of asma gravidade in adult...   \n",
              "6  Stress in the family is a source of stress for...   \n",
              "7  Increasing number of cardiovascular diseases i...   \n",
              "8  nepali nephritid patients are screened for inf...   \n",
              "9  Obesity is becoming a worldwide phenomenon and...   \n",
              "\n",
              "                            instruct_model_summaries  \n",
              "0   anxiety and depression are common in pd patients  \n",
              "1  Micrornas are small non - coding rnas that reg...  \n",
              "2  ohss is a complication of ovulation induction....  \n",
              "3  Congenital adrenal hyperplasia is a group of a...  \n",
              "4  Type 1 diabetes is a autoimmune disease charac...  \n",
              "5  A transversal study of asma gravidade in adult...  \n",
              "6  Stress in the family is a source of stress for...  \n",
              "7  Increasing number of cardiovascular diseases i...  \n",
              "8  nepali nephritid patients are screened for inf...  \n",
              "9  Obesity is becoming a worldwide phenomenon and...  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generar res√∫menes para evaluaci√≥n ROUGE en muestra de art√≠culos m√©dicos\n",
        "articles = dataset['test'][0:10]['article']\n",
        "human_baseline_summaries = dataset['test'][0:10]['abstract']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "\n",
        "print(\"Generando res√∫menes de art√≠culos m√©dicos para evaluaci√≥n...\")\n",
        "\n",
        "\n",
        "for idx, article in enumerate(articles):\n",
        "    article_truncated = article[:1000] + \"...\" if len(article) > 1000 else article\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "Summarize the following medical research article.\n",
        "\n",
        "{article_truncated}\n",
        "\n",
        "Summary: \"\"\"\n",
        "    \n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "    # Modelo original\n",
        "    original_model_outputs = original_model.generate(\n",
        "        input_ids=input_ids, \n",
        "        generation_config=GenerationConfig(max_new_tokens=120, num_beams=2) \n",
        "    )\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "\n",
        "    # Modelo \"fine-tuneado\"\n",
        "    instruct_model_outputs = instruct_model.generate(\n",
        "        input_ids=input_ids, \n",
        "        generation_config=GenerationConfig(max_new_tokens=120, num_beams=2)\n",
        "    )\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "    \n",
        "    print(f\"Procesado art√≠culo m√©dico {idx+1}/10\")\n",
        "\n",
        "# Crear DataFrame para visualizar resultados\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
        "df = pd.DataFrame(zipped_summaries, columns=['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
        "\n",
        "print(\"\\nPRIMEROS 3 EJEMPLOS DE RES√öMENES M√âDICOS:\")\n",
        "for i in range(min(3, len(df))):\n",
        "    print(f\"\\n--- ART√çCULO M√âDICO {i+1} ---\")\n",
        "    print(f\"Humano (Abstract): {df.iloc[i]['human_baseline_summaries'][:150]}...\")\n",
        "    print(f\"Original: {df.iloc[i]['original_model_summaries'][:150]}...\")\n",
        "    print(f\"Fine-tuned: {df.iloc[i]['instruct_model_summaries'][:150]}...\")\n",
        "\n",
        "print(f\"\\nDataFrame completo con {len(df)} res√∫menes m√©dicos:\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1sn5m_RV7ao",
        "tags": []
      },
      "source": [
        "Eval√∫e los modelos que calculan las m√©tricas ROUGE. ¬°Observe la mejora en los resultados!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VOEdyCI6V7ao",
        "outputId": "eeeabd00-a2b0-4756-896a-225e20e1fd2b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODELO ORIGINAL (Res√∫menes M√©dicos):\n",
            "   rouge1: 0.1112\n",
            "   rouge2: 0.0446\n",
            "   rougeL: 0.0953\n",
            "   rougeLsum: 0.1026\n",
            "\n",
            "MODELO CON FINE-TUNING (Res√∫menes M√©dicos):\n",
            "   rouge1: 0.1112\n",
            "   rouge2: 0.0446\n",
            "   rougeL: 0.0953\n",
            "   rougeLsum: 0.1026\n",
            "\n",
            "MEJORA ABSOLUTA:\n",
            "   rouge1: +0.00%\n",
            "   rouge2: +0.00%\n",
            "   rougeL: +0.00%\n",
            "   rougeLsum: +0.00%\n",
            "\n",
            "INTERPRETACI√ìN DE M√âTRICAS ROUGE:\n",
            "   - ROUGE-1: Overlap de palabras individuales (precisi√≥n general)\n",
            "   - ROUGE-2: Overlap de bigramas (fluidez y coherencia)\n",
            "   - ROUGE-L: Subsecuencia com√∫n m√°s larga (estructura)\n",
            "   - ROUGE-Lsum: ROUGE-L para res√∫menes multi-oraci√≥n\n"
          ]
        }
      ],
      "source": [
        "# Evaluar modelo original\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "# Evaluar modelo \"fine-tuneado\"\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('MODELO ORIGINAL (Res√∫menes M√©dicos):')\n",
        "for metric, score in original_model_results.items():\n",
        "    print(f'   {metric}: {score:.4f}')\n",
        "\n",
        "print('\\nMODELO CON FINE-TUNING (Res√∫menes M√©dicos):')\n",
        "for metric, score in instruct_model_results.items():\n",
        "    print(f'   {metric}: {score:.4f}')\n",
        "\n",
        "print('\\nMEJORA ABSOLUTA:')\n",
        "improvement = {k: instruct_model_results[k] - original_model_results[k] for k in original_model_results.keys()}\n",
        "for metric, improvement_score in improvement.items():\n",
        "    print(f'   {metric}: {improvement_score*100:+.2f}%')\n",
        "\n",
        "print('\\nINTERPRETACI√ìN DE M√âTRICAS ROUGE:')\n",
        "print('   - ROUGE-1: Overlap de palabras individuales (precisi√≥n general)')\n",
        "print('   - ROUGE-2: Overlap de bigramas (fluidez y coherencia)')\n",
        "print('   - ROUGE-L: Subsecuencia com√∫n m√°s larga (estructura)')\n",
        "print('   - ROUGE-Lsum: ROUGE-L para res√∫menes multi-oraci√≥n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aBoXNXzV7ap"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Fine-Tuning Eficiente de Par√°metros (PEFT) para Res√∫menes M√©dicos\n",
        "\n",
        "Ahora, realicemos un ajuste fino **PEFT** en lugar del ajuste fino completo, como se hizo anteriormente. PEFT es una forma de ajuste fino de instrucciones mucho m√°s eficiente que el ajuste fino completo, con resultados de evaluaci√≥n comparables, como ver√° pronto.\n",
        "\n",
        "PEFT es un t√©rmino gen√©rico que incluye **Adaptaci√≥n de Bajo Rango (LoRA)** y ajuste de prompts (¬°que NO ES LO MISMO que ingenier√≠a de prompts!). En la mayor√≠a de los casos, cuando alguien habla de PEFT, se refiere a LoRA. LoRA, a un nivel muy alto, permite al usuario ajustar su modelo utilizando menos recursos computacionales (en algunos casos, una sola GPU). \n",
        "\n",
        "Para res√∫menes m√©dicos, LoRA es especialmente √∫til porque:\n",
        "- Preserva el conocimiento m√©dico general del modelo base\n",
        "- Se enfoca en aprender patrones espec√≠ficos de resumen m√©dico\n",
        "- Requiere significativamente menos memoria y tiempo de entrenamiento\n",
        "- Permite crear m√∫ltiples adaptadores para diferentes especialidades m√©dicas\n",
        "\n",
        "Despu√©s del ajuste fino para res√∫menes m√©dicos con LoRA, el resultado es que el LLM original permanece sin cambios y surge un nuevo \"adaptador LoRA\". Este adaptador LoRA es mucho m√°s peque√±o que el LLM original: aproximadamente un porcentaje de un solo d√≠gito del tama√±o del LLM original (MB vs. GB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9hjS-tsV7ap"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "### 3.1 - Configuraci√≥n del modelo PEFT/LoRA para res√∫menes m√©dicos\n",
        "\n",
        "Debe configurar el modelo PEFT/LoRA para el ajuste fino con un nuevo adaptador de capa/par√°metro. Al usar PEFT/LoRA, se congela el LLM subyacente y solo se entrena el adaptador. Observe la configuraci√≥n de LoRA a continuaci√≥n, espec√≠ficamente ajustada para la tarea de resumen m√©dico. \n",
        "\n",
        "Note el hiperpar√°metro de rango (`r`), que define el rango/dimensi√≥n del adaptador que se va a entrenar. Para res√∫menes m√©dicos, usamos un rango ligeramente mayor para capturar mejor la complejidad de la terminolog√≠a m√©dica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iOjoDSwWV7ap",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05, \n",
        "    bias=\"none\", \n",
        "    task_type=TaskType.SEQ_2_SEQ_LM \n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMIM04QQV7ap",
        "tags": []
      },
      "source": [
        "Agregar capas/par√°metros del adaptador LoRA al LLM original para ser entrenado espec√≠ficamente para res√∫menes m√©dicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"Parametros entrenables del modelo: {trainable_model_params:,.0f}\\n Total de parametros del modelo: {all_model_params:,.0f}\\n Porcentaje de parametros entrenables {100 * trainable_model_params / all_model_params:.0f}%\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LnFsAZn-V7aq",
        "outputId": "f51c1974-cbb5-41ab-9fc9-33c458a7f804",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parametros entrenables del modelo: 3,538,944\n",
            " Total de parametros del modelo: 251,116,800\n",
            " Porcentaje de parametros entrenables 1%\n",
            "\n",
            "OMPARACI√ìN DE PAR√ÅMETROS:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\anfep\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "c:\\Users\\anfep\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "peft_model = get_peft_model(original_model, lora_config)\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(peft_model))\n",
        "\n",
        "\n",
        "print(f\"\\nOMPARACI√ìN DE PAR√ÅMETROS:\")\n",
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_ONKxTAV7aq",
        "tags": []
      },
      "source": [
        "<a name='3.2'></a>\n",
        "### 3.2 - Entrenar Adaptador PEFT para Res√∫menes M√©dicos\n",
        "\n",
        "Definir argumentos de entrenamiento espec√≠ficos para PEFT y crear instancia de `Trainer`. El entrenamiento PEFT para res√∫menes m√©dicos requiere ajustes espec√≠ficos en la tasa de aprendizaje y estrategia de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CN-Dbz23V7aq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "output_dir = f'./peft-medical-summarization-training-{str(int(time.time()))}'\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate=1e-3,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=1,\n",
        "    max_steps=50, \n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    save_steps=25,\n",
        "    warmup_steps=5,\n",
        "    load_best_model_at_end=True,\n",
        "    dataloader_drop_last=False,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHBCtG41V7aq"
      },
      "source": [
        "Now everything is ready to train the PEFT adapter and save the model.\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DpmZQBsMV7aq",
        "outputId": "190e13b1-4dfe-4fd6-ea51-5da0c34eaf98",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\anfep\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 53:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.274676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.703100</td>\n",
              "      <td>2.848214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\anfep\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./peft-dialogue-summary-checkpoint-local\\\\tokenizer_config.json',\n",
              " './peft-dialogue-summary-checkpoint-local\\\\special_tokens_map.json',\n",
              " './peft-dialogue-summary-checkpoint-local\\\\spiece.model',\n",
              " './peft-dialogue-summary-checkpoint-local\\\\added_tokens.json',\n",
              " './peft-dialogue-summary-checkpoint-local\\\\tokenizer.json')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_trainer.train()\n",
        "peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3voqLpwV7aq",
        "tags": []
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6G7nD1SV7aq",
        "tags": []
      },
      "source": [
        "That training was performed on a subset of data. To load a fully trained PEFT model, read a checkpoint of a PEFT model from S3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzVDgXwAV7aq",
        "outputId": "703611af-2548-443d-87da-747fa955865d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_config.json to peft-dialogue-summary-checkpoint-from-s3/adapter_config.json\n",
            "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/special_tokens_map.json to peft-dialogue-summary-checkpoint-from-s3/special_tokens_map.json\n",
            "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer_config.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer_config.json\n",
            "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/tokenizer.json to peft-dialogue-summary-checkpoint-from-s3/tokenizer.json\n",
            "download: s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/adapter_model.bin to peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin\n"
          ]
        }
      ],
      "source": [
        "#!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ./peft-dialogue-summary-checkpoint-from-s3/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbW58BYaV7ar",
        "tags": []
      },
      "source": [
        "Comprueba que el tama√±o de este modelo es mucho menor que el LLM original:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2LTOlgbV7ar",
        "outputId": "f0e1074b-8b24-40be-f29f-cf104db1b0bc",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "El sistema no puede encontrar la ruta especificada.\n"
          ]
        }
      ],
      "source": [
        "!dir /a .\\peft-dialogue-summary-checkpoint-from-s3\\adapter_model.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886lESmdV7ar",
        "tags": []
      },
      "source": [
        "Prepare este modelo a√±adiendo un adaptador al modelo FLAN-T5 original. Est√° configurando `is_trainable=False` porque el plan es realizar inferencia √∫nicamente con este modelo PEFT. Si estuviera preparando el modelo para entrenamiento posterior, deber√≠a configurar `is_trainable=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5FCVCdu8V7ar",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "\n",
        "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(\n",
        "    peft_model_base,\n",
        "    './peft-dialogue-summary-checkpoint-local/', \n",
        "    torch_dtype=torch.bfloat16,\n",
        "    is_trainable=True  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uretNB0sV7ar",
        "tags": []
      },
      "source": [
        "The number of trainable parameters will be `0` due to `is_trainable=False` setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "HqWoJBCrV7ar",
        "outputId": "0377ef7e-bd4a-42af-d559-788b9c4b6b89",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parametros entrenables del modelo: 3,538,944\n",
            " Total de parametros del modelo: 251,116,800\n",
            " Porcentaje de parametros entrenables 1%\n"
          ]
        }
      ],
      "source": [
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywXzSfTrV7ar"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "### 3.3 - Evaluate the Model Qualitatively (Human Evaluation)\n",
        "\n",
        "Make inferences for the same example as in sections [1.3](#1.3) and [2.3](#2.3), with the original model, fully fine-tuned and PEFT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Cpcpbtj1V7as",
        "outputId": "ffd18e06-ab2c-438e-86bd-4b27af6644e8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "ART√çCULO M√âDICO (MUESTRA):\n",
            "radiocontrast - induced nephropathy ( rin ) can lead to acute renal failure ( arf ) , which may require dialysis therapy . \n",
            " arf increases treatment cost due to sepsis , hemorrhage , respiratory failure , and a long hospitalization.[13 ] rin is an important cause of hospital - acquired arf and is re...\n",
            "----------------------------------------------------------------------------------------------------\n",
            "RESUMEN HUMANO (BASELINE):\n",
            "radiocontrast administration is an important cause of acute renal failure . in this study , \n",
            " compared the plasma creatinine levels with spot urine il-18 levels following radiocontrast administration . \n",
            " twenty patients ( 11 males , 9 females ) underwent radiocontrast diagnostic and therapeutic - enhanced examinations . \n",
            " the rin mehran risk score was low ( 5 ) . \n",
            " the radiocontrast agents used were 623 mg / ml iopromid ( 1.5 ml / kg ) , and 100 ml of 650 mg / ml meglumine diatrizoate as three - way oral and rectal contrast material for abdominal computed tomography ( ct ) scans . \n",
            " serum blood urea nitrogen , creatinine , na , k , cl , ca , p , creatinine clearance , and spot urine il-18 levels were analyzed before and repeated at 24 , 48 , and 72 h after radiocontrast administration . \n",
            " six and 24-h urinary il-18 levels were measured with a human il-18 elisa kit following radiocontrast administration . \n",
            " an increase in plasma creatinine 24 and 48 h following radiocontrast administration was observed compared with precontrast values , but it was not statistically significant ( p=0.052 and p=0.285 , respectively ) . a statistically significant increase in il-18 levels was observed at 6 and 24 h , compared with precontrast values ( p=0.048 and p=0.028 , respectively ) . \n",
            " a tendency for postcontrast 24-h urinary il-18 levels to increase was observed compared with 6 h , but the increase was not statistically significant ( p=0.808 ) . \n",
            " our results show that plasma creatinine starts to increase at 24th hour ; however , spot urine il-18 levels go up at 6th hour following radiocontrast administration implying urine il-18 to be an earlier parameter for kidney injury .\n",
            "----------------------------------------------------------------------------------------------------\n",
            "MODELO ORIGINAL (Sin Fine-tuning):\n",
            "rin is a risk factor for hospital - acquired arf . the risk factors for rin include current renal insufficiency , diabetes mellitus , and high contrast volume . the risk factors for rin include current renal insufficiency , diabetes mellitus , and high contrast volume . the risk factors for rin include current renal insufficiency , diabetes mellitus , and high contrast volume . the risk factors for rin include current renal insuff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "MODELO FULL FINE-TUNING:\n",
            "Radiocontrast nephropathy is a risk factor for hospital-acquired arf.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "MODELO PEFT:\n",
            "rin is a risk factor for hospital - acquired arf . the risk factors for rin include current renal insufficiency , diabetes mellitus , and high contrast volume . the risk factors for rin include current renal insufficiency , diabetes mellitus , and high contrast volume . the risk factors for rin include current renal insufficiency , diabetes mellitus , and high contrast volume . the risk factors for rin include current renal insuff\n",
            "\n",
            "AN√ÅLISIS COMPARATIVO:\n",
            "M√âTRICAS COMPARATIVAS:\n",
            "                    Original  Full-FT   PEFT\n",
            "Longitud:                74        9    74\n",
            "T√©rminos m√©dicos:         1        0     1\n",
            "Similitud:            0.480    0.556  0.480\n"
          ]
        }
      ],
      "source": [
        "index = 25\n",
        "article = dataset['test'][index]['article']\n",
        "baseline_human_summary = dataset['test'][index]['abstract']\n",
        "\n",
        "\n",
        "article_for_models = article[:1000] + \"...\" if len(article) > 1000 else article\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following medical research article.\n",
        "\n",
        "{article_for_models}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "\n",
        "# Modelo original (sin fine-tuning)\n",
        "original_model_outputs = original_model.generate(\n",
        "    input_ids=input_ids, \n",
        "    generation_config=GenerationConfig(max_new_tokens=120, num_beams=1)\n",
        ")\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Modelo con full fine-tuning (simulado)\n",
        "instruct_model_outputs = instruct_model.generate(\n",
        "    input_ids=input_ids, \n",
        "    generation_config=GenerationConfig(max_new_tokens=120, num_beams=1)\n",
        ")\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Modelo PEFT (simulado)\n",
        "peft_model_outputs = peft_model.generate(\n",
        "    input_ids=input_ids, \n",
        "    generation_config=GenerationConfig(max_new_tokens=120, num_beams=1)\n",
        ")\n",
        "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "dash_line = '-' * 100\n",
        "print(dash_line)\n",
        "print(f'ART√çCULO M√âDICO (MUESTRA):')\n",
        "print(f'{article_for_models[:300]}...')\n",
        "print(dash_line)\n",
        "print(f'RESUMEN HUMANO (BASELINE):\\n{baseline_human_summary}')\n",
        "print(dash_line)\n",
        "print(f'MODELO ORIGINAL (Sin Fine-tuning):\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'MODELO FULL FINE-TUNING:\\n{instruct_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'MODELO PEFT:\\n{peft_model_text_output}')\n",
        "\n",
        "print(f\"\\nAN√ÅLISIS COMPARATIVO:\")\n",
        "\n",
        "def analyze_medical_summary_advanced(summary, reference):\n",
        "    \"\"\"An√°lisis avanzado de res√∫menes m√©dicos\"\"\"\n",
        "    summary_words = set(summary.lower().split())\n",
        "    reference_words = set(reference.lower().split())\n",
        "    \n",
        "    # T√©rminos m√©dicos especializados\n",
        "    medical_terms = {\n",
        "        'patient', 'treatment', 'study', 'clinical', 'therapy', 'disease', \n",
        "        'diagnosis', 'medical', 'health', 'hospital', 'symptoms', 'condition',\n",
        "        'research', 'analysis', 'results', 'outcome', 'intervention', 'care'\n",
        "    }\n",
        "    \n",
        "    # M√©tricas\n",
        "    summary_medical = len(summary_words.intersection(medical_terms))\n",
        "    overlap = len(summary_words.intersection(reference_words))\n",
        "    \n",
        "    return {\n",
        "        'length': len(summary.split()),\n",
        "        'medical_terms': summary_medical,\n",
        "        'word_overlap': overlap,\n",
        "        'similarity': overlap / max(len(summary_words), 1)\n",
        "    }\n",
        "\n",
        "# An√°lisis de los tres modelos\n",
        "orig_analysis = analyze_medical_summary_advanced(original_model_text_output, baseline_human_summary)\n",
        "inst_analysis = analyze_medical_summary_advanced(instruct_model_text_output, baseline_human_summary)\n",
        "peft_analysis = analyze_medical_summary_advanced(peft_model_text_output, baseline_human_summary)\n",
        "\n",
        "print(f\"M√âTRICAS COMPARATIVAS:\")\n",
        "print(f\"                    Original  Full-FT   PEFT\")\n",
        "print(f\"Longitud:          {orig_analysis['length']:8d}  {inst_analysis['length']:7d}  {peft_analysis['length']:4d}\")\n",
        "print(f\"T√©rminos m√©dicos:  {orig_analysis['medical_terms']:8d}  {inst_analysis['medical_terms']:7d}  {peft_analysis['medical_terms']:4d}\")\n",
        "print(f\"Similitud:         {orig_analysis['similarity']:8.3f}  {inst_analysis['similarity']:7.3f}  {peft_analysis['similarity']:4.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waRMtMeRV7as"
      },
      "source": [
        "<a name='3.4'></a>\n",
        "### 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "Perform inferences for the sample of the test dataset (only 10 dialogues and summaries to save time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "gVyu4NbDV7as",
        "outputId": "101fbfeb-b679-4fcf-d1ea-1d06540bed59",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¨ EVALUACI√ìN CUANTITATIVA DE RES√öMENES M√âDICOS...\n",
            "‚è±Ô∏è  Generando res√∫menes con los tres enfoques...\n",
            "Art√≠culo m√©dico 1/10 procesado\n",
            "Art√≠culo m√©dico 2/10 procesado\n",
            "Art√≠culo m√©dico 3/10 procesado\n",
            "Art√≠culo m√©dico 4/10 procesado\n",
            "Art√≠culo m√©dico 5/10 procesado\n",
            "Art√≠culo m√©dico 6/10 procesado\n",
            "Art√≠culo m√©dico 7/10 procesado\n",
            "Art√≠culo m√©dico 8/10 procesado\n",
            "Art√≠culo m√©dico 9/10 procesado\n",
            "Art√≠culo m√©dico 10/10 procesado\n",
            "\n",
            "MUESTRA DE RESULTADOS (Primeros 2 ejemplos):\n",
            "\n",
            "--- ART√çCULO M√âDICO 1 ---\n",
            "Humano: research on the implications of anxiety in parkinson 's disease ( pd ) has been neglected despite it...\n",
            "Original: anxiety and depression are common in pd patients . anxiety and depression are common in pd patients ...\n",
            "Full-FT: anxiety and depression are common in pd patients...\n",
            "PEFT: anxiety and depression are common in pd patients . anxiety and depression are common in pd patients ...\n",
            "\n",
            "--- ART√çCULO M√âDICO 2 ---\n",
            "Humano: small non - coding rnas include sirna , mirna , pirna and snorna . \n",
            " the involvement of mirnas in th...\n",
            "Original: a class of small non - coding rnas , known as mirnas , are a class of small non - coding rnas . mirn...\n",
            "Full-FT: mrnas are small non - coding RNAs that regulate the stability or translational efficiency of targete...\n",
            "PEFT: a class of small non - coding rnas , known as mirnas , is a class of small non - coding rnas . mirna...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "      <th>peft_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>research on the implications of anxiety in par...</td>\n",
              "      <td>anxiety and depression are common in pd patien...</td>\n",
              "      <td>anxiety and depression are common in pd patients</td>\n",
              "      <td>anxiety and depression are common in pd patien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>small non - coding rnas include sirna , mirna ...</td>\n",
              "      <td>a class of small non - coding rnas , known as ...</td>\n",
              "      <td>mrnas are small non - coding RNAs that regulat...</td>\n",
              "      <td>a class of small non - coding rnas , known as ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>objective : to evaluate the efficacy and safet...</td>\n",
              "      <td>ohss is a complication of ovulation induction ...</td>\n",
              "      <td>ohss is a complication of ovulation induction....</td>\n",
              "      <td>ohss is a complication of ovulation induction ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>congenital adrenal hyperplasia is a group of a...</td>\n",
              "      <td>adreno cortico trophic hormone ( ac ) deficien...</td>\n",
              "      <td>Acute congenital adrenal hyperplasia in children.</td>\n",
              "      <td>adreno cortico trophic hormone ( ac ) deficien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>objective(s):pentoxifylline is an immunomodula...</td>\n",
              "      <td>t1d is a disease that is mediated by the immun...</td>\n",
              "      <td>Type 1 diabetes is a autoimmune disease charac...</td>\n",
              "      <td>t1d is a disease that is mediated by the immun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>abstractobjective : to determine the presence ...</td>\n",
              "      <td>a transversal study , a transversal study , a ...</td>\n",
              "      <td>A transversal study of asma gravidade in adult...</td>\n",
              "      <td>a transversal study , a transversal study , a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>background : since the family is a social syst...</td>\n",
              "      <td>stress in the family is a source of stress for...</td>\n",
              "      <td>Stress in the family is a source of stress for...</td>\n",
              "      <td>stress in the family is a source of stress for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>background and objective :   anxiety and depre...</td>\n",
              "      <td>cardiovascular disease is a disease that cause...</td>\n",
              "      <td>The disease pattern has changed from tradition...</td>\n",
              "      <td>Cardiovascular diseases are a major health pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>worldwide emergence of variant viruses has pro...</td>\n",
              "      <td>nepal 's armed forces research institute for m...</td>\n",
              "      <td>nepali nephritid patients with influenza-like ...</td>\n",
              "      <td>nepal 's armed forces research institute for m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>excess weight has generally been associated wi...</td>\n",
              "      <td>obesity is a health problem . obesity is a ris...</td>\n",
              "      <td>obesity is becoming a worldwide phenomenon</td>\n",
              "      <td>obesity is a health problem . obesity is a ris...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  research on the implications of anxiety in par...   \n",
              "1  small non - coding rnas include sirna , mirna ...   \n",
              "2  objective : to evaluate the efficacy and safet...   \n",
              "3  congenital adrenal hyperplasia is a group of a...   \n",
              "4  objective(s):pentoxifylline is an immunomodula...   \n",
              "5  abstractobjective : to determine the presence ...   \n",
              "6  background : since the family is a social syst...   \n",
              "7  background and objective :   anxiety and depre...   \n",
              "8  worldwide emergence of variant viruses has pro...   \n",
              "9  excess weight has generally been associated wi...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  anxiety and depression are common in pd patien...   \n",
              "1  a class of small non - coding rnas , known as ...   \n",
              "2  ohss is a complication of ovulation induction ...   \n",
              "3  adreno cortico trophic hormone ( ac ) deficien...   \n",
              "4  t1d is a disease that is mediated by the immun...   \n",
              "5  a transversal study , a transversal study , a ...   \n",
              "6  stress in the family is a source of stress for...   \n",
              "7  cardiovascular disease is a disease that cause...   \n",
              "8  nepal 's armed forces research institute for m...   \n",
              "9  obesity is a health problem . obesity is a ris...   \n",
              "\n",
              "                            instruct_model_summaries  \\\n",
              "0   anxiety and depression are common in pd patients   \n",
              "1  mrnas are small non - coding RNAs that regulat...   \n",
              "2  ohss is a complication of ovulation induction....   \n",
              "3  Acute congenital adrenal hyperplasia in children.   \n",
              "4  Type 1 diabetes is a autoimmune disease charac...   \n",
              "5  A transversal study of asma gravidade in adult...   \n",
              "6  Stress in the family is a source of stress for...   \n",
              "7  The disease pattern has changed from tradition...   \n",
              "8  nepali nephritid patients with influenza-like ...   \n",
              "9         obesity is becoming a worldwide phenomenon   \n",
              "\n",
              "                                peft_model_summaries  \n",
              "0  anxiety and depression are common in pd patien...  \n",
              "1  a class of small non - coding rnas , known as ...  \n",
              "2  ohss is a complication of ovulation induction ...  \n",
              "3  adreno cortico trophic hormone ( ac ) deficien...  \n",
              "4  t1d is a disease that is mediated by the immun...  \n",
              "5  a transversal study , a transversal study , a ...  \n",
              "6  stress in the family is a source of stress for...  \n",
              "7  Cardiovascular diseases are a major health pro...  \n",
              "8  nepal 's armed forces research institute for m...  \n",
              "9  obesity is a health problem . obesity is a ris...  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "articles = dataset['test'][0:10]['article']\n",
        "human_baseline_summaries = dataset['test'][0:10]['abstract']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "peft_model_summaries = []\n",
        "\n",
        "print(\"EVALUACI√ìN CUANTITATIVA DE RES√öMENES M√âDICOS...\")\n",
        "print(\"Generando res√∫menes con los tres enfoques...\")\n",
        "\n",
        "for idx, article in enumerate(articles):\n",
        "    article_truncated = article[:1000] + \"...\" if len(article) > 1000 else article\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "Summarize the following medical research article.\n",
        "\n",
        "{article_truncated}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "    # Resumen humano baseline\n",
        "    human_baseline_text_output = human_baseline_summaries[idx]\n",
        "\n",
        "    # Modelo original\n",
        "    original_model_outputs = original_model.generate(\n",
        "        input_ids=input_ids, \n",
        "        generation_config=GenerationConfig(max_new_tokens=120)\n",
        "    )\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Modelo full fine-tuning\n",
        "    instruct_model_outputs = instruct_model.generate(\n",
        "        input_ids=input_ids, \n",
        "        generation_config=GenerationConfig(max_new_tokens=120)\n",
        "    )\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Modelo PEFT\n",
        "    peft_model_outputs = peft_model.generate(\n",
        "        input_ids=input_ids, \n",
        "        generation_config=GenerationConfig(max_new_tokens=120)\n",
        "    )\n",
        "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Almacenar res√∫menes\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "    peft_model_summaries.append(peft_model_text_output)\n",
        "    \n",
        "    print(f\"Art√≠culo m√©dico {idx+1}/10 procesado\")\n",
        "\n",
        "# Crear DataFrame comparativo\n",
        "zipped_summaries = list(zip(\n",
        "    human_baseline_summaries, \n",
        "    original_model_summaries, \n",
        "    instruct_model_summaries, \n",
        "    peft_model_summaries\n",
        "))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns=[\n",
        "    'human_baseline_summaries', \n",
        "    'original_model_summaries', \n",
        "    'instruct_model_summaries', \n",
        "    'peft_model_summaries'\n",
        "])\n",
        "\n",
        "print(\"\\nMUESTRA DE RESULTADOS (Primeros 2 ejemplos):\")\n",
        "for i in range(min(2, len(df))):\n",
        "    print(f\"\\n--- ART√çCULO M√âDICO {i+1} ---\")\n",
        "    print(f\"Humano: {df.iloc[i]['human_baseline_summaries'][:100]}...\")\n",
        "    print(f\"Original: {df.iloc[i]['original_model_summaries'][:100]}...\")\n",
        "    print(f\"Full-FT: {df.iloc[i]['instruct_model_summaries'][:100]}...\")\n",
        "    print(f\"PEFT: {df.iloc[i]['peft_model_summaries'][:100]}...\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Calcule la puntuaci√≥n ROUGE para este subconjunto de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-3HrajATV7as",
        "outputId": "e9b28422-36cf-424e-f99c-638346673210",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CALCULANDO M√âTRICAS ROUGE COMPARATIVAS...\n",
            "RESULTADOS ROUGE PARA RES√öMENES M√âDICOS:\n",
            "============================================================\n",
            "MODELO ORIGINAL:\n",
            "   rouge1: 0.1410\n",
            "   rouge2: 0.0252\n",
            "   rougeL: 0.1119\n",
            "   rougeLsum: 0.1323\n",
            "\n",
            "MODELO FULL FINE-TUNING:\n",
            "   rouge1: 0.0677\n",
            "   rouge2: 0.0210\n",
            "   rougeL: 0.0573\n",
            "   rougeLsum: 0.0602\n",
            "\n",
            "MODELO PEFT:\n",
            "   rouge1: 0.1414\n",
            "   rouge2: 0.0254\n",
            "   rougeL: 0.1127\n",
            "   rougeLsum: 0.1333\n",
            "\n",
            "TABLA COMPARATIVA:\n",
            "M√©trica      Original   Full-FT    PEFT      \n",
            "------------ ---------- ---------- ----------\n",
            "rouge1       0.1410     0.0677     0.1414    \n",
            "rouge2       0.0252     0.0210     0.0254    \n",
            "rougeL       0.1119     0.0573     0.1127    \n",
            "rougeLsum    0.1323     0.0602     0.1333    \n"
          ]
        }
      ],
      "source": [
        "# Calcular m√©tricas ROUGE para los tres enfoques\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "print(\"CALCULANDO M√âTRICAS ROUGE COMPARATIVAS...\")\n",
        "\n",
        "# Modelo original\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "# Modelo full fine-tuning\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "# Modelo PEFT\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('RESULTADOS ROUGE PARA RES√öMENES M√âDICOS:')\n",
        "print('='*60)\n",
        "\n",
        "print('MODELO ORIGINAL:')\n",
        "for metric, score in original_model_results.items():\n",
        "    print(f'   {metric}: {score:.4f}')\n",
        "\n",
        "print('\\nMODELO FULL FINE-TUNING:')\n",
        "for metric, score in instruct_model_results.items():\n",
        "    print(f'   {metric}: {score:.4f}')\n",
        "\n",
        "print('\\nMODELO PEFT:')\n",
        "for metric, score in peft_model_results.items():\n",
        "    print(f'   {metric}: {score:.4f}')\n",
        "\n",
        "# An√°lisis comparativo\n",
        "print(f\"\\nTABLA COMPARATIVA:\")\n",
        "print(f\"{'M√©trica':<12} {'Original':<10} {'Full-FT':<10} {'PEFT':<10}\")\n",
        "print(f\"{'-'*12} {'-'*10} {'-'*10} {'-'*10}\")\n",
        "for metric in original_model_results.keys():\n",
        "    print(f\"{metric:<12} {original_model_results[metric]:<10.4f} \"\n",
        "          f\"{instruct_model_results[metric]:<10.4f} {peft_model_results[metric]:<10.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4mO5W3cV7at"
      },
      "source": [
        "Notice, that PEFT model results are not too bad, while the training process was much easier!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjF00HfCV7at"
      },
      "source": [
        "The results show less of an improvement over full fine-tuning, but the benefits of PEFT typically outweigh the slightly-lower performance metrics.\n",
        "\n",
        "Calculate the improvement of PEFT over the original model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pIjy_UjPV7at",
        "outputId": "a5791413-b9c4-40cf-e01c-5d997a808244",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\n",
            "rouge1: 0.05%\n",
            "rouge2: 0.02%\n",
            "rougeL: 0.09%\n",
            "rougeLsum: 0.10%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOAnR7g0V7at"
      },
      "source": [
        "Now calculate the improvement of PEFT over a full fine-tuned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "vi4WUIjGV7at",
        "outputId": "66b8dfe4-c54a-4d76-bdb0-bd57f0d2234f",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\n",
            "rouge1: 7.37%\n",
            "rouge2: 0.44%\n",
            "rougeL: 5.55%\n",
            "rougeLsum: 7.31%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "instance_type": "ml.m5.2xlarge",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
